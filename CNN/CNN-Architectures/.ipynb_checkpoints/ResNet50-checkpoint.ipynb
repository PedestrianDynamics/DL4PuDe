{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2c361a",
   "metadata": {},
   "source": [
    "\n",
    "# ResNet50\n",
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39658a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d459a2ea",
   "metadata": {},
   "source": [
    "### Building a ResNet50\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe7474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           131136      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            65          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,718,913\n",
      "Trainable params: 23,665,793\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 224,224\n",
    "\n",
    "model = ResNet50(weights='imagenet',input_shape=(img_rows, img_cols, 3), include_top=False)\n",
    " \n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "top_model =model.output\n",
    "top_model = GlobalAveragePooling2D()(top_model)\n",
    "top_model = Dense(64,activation='relu')(top_model)\n",
    "top_model = Dropout(0.5)(top_model)\n",
    "output = Dense(1,activation='sigmoid')(top_model)\n",
    " \n",
    "model = Model(inputs = model.input, outputs = output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef5473",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb32183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, to_file='Models/SimpleCNN_model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da516c",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e76f8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3156 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 638 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'non-pushing': 0, 'pushing': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "train_data_dir = 'Dataset path/train'\n",
    "validation_data_dir = 'Dataset path/validation'\n",
    "test_data_dir = 'Dataset path/test'\n",
    " \n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    " \n",
    "batch_size = 128\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "# Fetching x_train, y_train variables from train_generator.\n",
    "train_generator.reset()\n",
    "x_train, y_train = next(train_generator)\n",
    "for i in range(len(train_generator)-1): # \n",
    "    img, label = next(train_generator)\n",
    "    x_train = np.append(x_train, img, axis=0 )\n",
    "    y_train = np.append(y_train, label, axis=0)\n",
    " \n",
    " \n",
    "# Fetching x_tvalidation, y_validation variables from validation_generator.    \n",
    "validation_generator.reset()\n",
    "x_validation, y_validation = next(validation_generator)\n",
    "for i in range(len(validation_generator)-1): \n",
    "    img, label = next(validation_generator)\n",
    "    x_validation = np.append(x_validation, img, axis=0 )\n",
    "    y_validation = np.append(y_validation, label, axis=0)\n",
    "    \n",
    "# Fetching x_test, y_test variables from test.    \n",
    "test_generator.reset()\n",
    "x_test, y_test = next(test_generator)\n",
    "for i in range(len(test_generator)-1): \n",
    "    img, label = next(test_generator)\n",
    "    x_test = np.append(x_test, img, axis=0 )\n",
    "    y_test = np.append(y_test, label, axis=0)\n",
    "    \n",
    "nb_train_samples = len(x_train)\n",
    "nb_validation_samples = len(x_validation) \n",
    "nb_test_samples = len(x_test) \n",
    "    \n",
    " \n",
    "    \n",
    "validation_generator.class_indices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09595e3d",
   "metadata": {},
   "source": [
    "### Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99c2da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 541s 22s/step - loss: 0.8404 - accuracy: 0.5951 - val_loss: 0.6927 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54487, saving model to ./Models/ResNet50.h5\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 548s 22s/step - loss: 0.5422 - accuracy: 0.7614 - val_loss: 804.2002 - val_accuracy: 0.4551\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.54487\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 553s 22s/step - loss: 0.4676 - accuracy: 0.7982 - val_loss: 2144.8533 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.54487\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 549s 22s/step - loss: 0.4198 - accuracy: 0.8235 - val_loss: 83.4098 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.54487\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 552s 22s/step - loss: 0.4112 - accuracy: 0.8302 - val_loss: 136.2323 - val_accuracy: 0.4551\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.54487\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 557s 22s/step - loss: 0.4085 - accuracy: 0.8308 - val_loss: 133.3441 - val_accuracy: 0.4551\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.54487\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 553s 22s/step - loss: 0.3625 - accuracy: 0.8470 - val_loss: 0.6958 - val_accuracy: 0.4760\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.54487\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 555s 22s/step - loss: 0.3224 - accuracy: 0.8682 - val_loss: 3606.6943 - val_accuracy: 0.4551\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.54487\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.2933 - accuracy: 0.8824 - val_loss: 1.0568 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.54487\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.2434 - accuracy: 0.9068 - val_loss: 1.0240 - val_accuracy: 0.6346\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.54487 to 0.63462, saving model to ./Models/ResNet50.h5\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 558s 22s/step - loss: 0.2440 - accuracy: 0.9160 - val_loss: 2.8678 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.63462\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 558s 22s/step - loss: 0.1792 - accuracy: 0.9293 - val_loss: 0.6921 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.63462\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 556s 22s/step - loss: 0.1604 - accuracy: 0.9369 - val_loss: 13.2938 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.63462\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 552s 22s/step - loss: 0.1377 - accuracy: 0.9525 - val_loss: 12.3405 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.63462\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.1125 - accuracy: 0.9629 - val_loss: 5.1338 - val_accuracy: 0.6362\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.63462 to 0.63622, saving model to ./Models/ResNet50.h5\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0933 - accuracy: 0.9712 - val_loss: 2.0078 - val_accuracy: 0.5048\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.63622\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0971 - accuracy: 0.9620 - val_loss: 5.0964 - val_accuracy: 0.4808\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.63622\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0940 - accuracy: 0.9677 - val_loss: 7.1356 - val_accuracy: 0.4840\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.63622\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 555s 22s/step - loss: 0.0617 - accuracy: 0.9807 - val_loss: 2.5252 - val_accuracy: 0.5112\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.63622\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 555s 22s/step - loss: 0.0680 - accuracy: 0.9762 - val_loss: 1.3515 - val_accuracy: 0.4728\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.63622\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 551s 22s/step - loss: 0.0884 - accuracy: 0.9766 - val_loss: 4.6916 - val_accuracy: 0.6026\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.63622\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 3.4220 - val_accuracy: 0.5208\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.63622\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 1.8543 - val_accuracy: 0.5321\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.63622\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 3.6836 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.63622\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0420 - accuracy: 0.9886 - val_loss: 1.4170 - val_accuracy: 0.4872\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.63622\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0673 - accuracy: 0.9838 - val_loss: 2.3014 - val_accuracy: 0.5641\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.63622\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0419 - accuracy: 0.9851 - val_loss: 1.7702 - val_accuracy: 0.6891\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.63622 to 0.68910, saving model to ./Models/ResNet50.h5\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 11.5012 - val_accuracy: 0.5465\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68910\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0669 - accuracy: 0.9870 - val_loss: 5.7027 - val_accuracy: 0.4824\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68910\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0184 - accuracy: 0.9927 - val_loss: 11.9424 - val_accuracy: 0.5465\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.68910\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 1.5736 - val_accuracy: 0.6298\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.68910\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 4.9291 - val_accuracy: 0.5337\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.68910\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 7.2889 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.68910\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 72.5132 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.68910\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0507 - accuracy: 0.9870 - val_loss: 1.4702 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.68910\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 23.3888 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.68910\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0355 - accuracy: 0.9886 - val_loss: 1.1316 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.68910 to 0.69712, saving model to ./Models/ResNet50.h5\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 1.1206 - val_accuracy: 0.7580\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.69712 to 0.75801, saving model to ./Models/ResNet50.h5\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 49.2930 - val_accuracy: 0.3958\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75801\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 2.0705 - val_accuracy: 0.4856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75801\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0232 - accuracy: 0.9949 - val_loss: 1.7185 - val_accuracy: 0.5865\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75801\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0286 - accuracy: 0.9930 - val_loss: 2.6595 - val_accuracy: 0.5369\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75801\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 1.3764 - val_accuracy: 0.6426\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75801\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 3.8688 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.75801 to 0.76923, saving model to ./Models/ResNet50.h5\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 2.8215 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76923\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 2.0412 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76923\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.1217 - accuracy: 0.9788 - val_loss: 11.9635 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76923\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 551s 22s/step - loss: 0.1002 - accuracy: 0.9943 - val_loss: 6.1089 - val_accuracy: 0.4824\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76923\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 551s 22s/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 1.8961 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76923\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 3.1466 - val_accuracy: 0.5337\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76923\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 5.8125 - val_accuracy: 0.5465\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.76923\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 2.6162 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.76923\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0223 - accuracy: 0.9918 - val_loss: 2.4317 - val_accuracy: 0.5593\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.76923\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 549s 22s/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 2.5459 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.76923\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 552s 22s/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 1.5029 - val_accuracy: 0.6138\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.76923\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 3.6379 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.76923\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 1.3144 - val_accuracy: 0.6683\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.76923\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0436 - accuracy: 0.9902 - val_loss: 10.6784 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.76923\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 10.9959 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.76923\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 550s 22s/step - loss: 0.0465 - accuracy: 0.9905 - val_loss: 9.0960 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.76923\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 554s 22s/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 1.0411 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.76923\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 554s 22s/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 7.0281 - val_accuracy: 0.4712\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.76923\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 554s 22s/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 7.8443 - val_accuracy: 0.5449\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.76923\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 551s 22s/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 6.1395 - val_accuracy: 0.5433\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.76923\n",
      "Epoch 00064: early stopping\n",
      " Time:  35260.53117990494\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "        \n",
    "checkpoint = ModelCheckpoint(\"./Models/ResNet50.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', \n",
    "                          min_delta = 0, \n",
    "                          patience = 20,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "\n",
    "# Enter the number of training and validation samples here\n",
    "nb_train_samples = len(x_train)\n",
    "nb_validation_samples = len(x_test)\n",
    "\n",
    "epochs = 100 \n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator \n",
    "    )\n",
    "\n",
    "end = time.time()    \n",
    "print(f\" Time:  {end-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
